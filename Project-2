Penalized logisistic Regression and random forest models are from R:


Below are the output from top_models:




The AUC curve can be found below:

lr_plot


Q: Are you able to use the feature selection penalty to tune your hyperparameter and remove any potentially irrelevant predictors?

###Yes, I selected the penalty value from model 11, 0.00108, as the penalty. I think this did remove some irrelevant predictors. However, the AUC for model 11 was not significantly different from models 1 through 13, so I am unsure how much using the .00108 penalty improved the model as compared to the other options.

Q: Provide justification for your selected penalty value?

####I selected the penalty value of 0.00108 because it fell in the middle of the range of penalty values in the 15 models created by the top_models. I ran all the different slices to look at the ROC plots and compare them. When n=15, there is not a huge difference between the models. However, I also tried running top_models with n= 30, and I then looked at the ROC plot for the 30th model (below). When I used slice(30), as you can see, the plots are all basically straight 45 degree lines. So in comparing the slices 1 through 15 to this plot, I found that slice 11 seemed like the plot had slightly bigger AUC than the other slices, although it is hard to be precise.


####The AUC to penalty curve can be found below. Note that the x-axis is not in a linear scale, equidistant points on the x direction share the same ratio in penalty values instead of difference.

(((((lr_plot here:))))

###It appears that the AUC gradually decreased from the first model (penalty value = 0.001) to the 21st model (penalty value = 0.0117210), and stayed steady towards the 24th model (penalty value = 0.0239503), after which the AUC dropped significantly, then stayed steady again from the 27th model (penalty value = 0.0489390) to the 29th model (penalty value = 0.0788046). From this, I think the irrelevant predictors are gradually removed from the model throughout the first to 21st model (penalty value from 0.001 to 0.0117210), after which relevant predictors were removed from the model, resulting in significant drops in the AUC.

##I choose the penalty value of 0.000853168 (the 10th model) because it is represented by the last point in the plot that belongs to the initial gradual descent in AUC.

##The ROC plot of the model is as follows:

((((lr_auc plot here:))))






BELOW ARE FROM PYTHON.  

MODEL 3
Here are the evaluative metrics:
(((FRom python code, then view result in bottom right)))
{'accuracy': 0.8678867, 'accuracy_baseline': 0.86151326, 'auc': 0.80184686, 'auc_precision_recall': 0.377051, 'average_loss': 0.31925312, 'label/mean': 0.13848676, 'loss': 0.31925312, 'precision': 0.58536583, 'prediction/mean': 0.14456409, 'recall': 0.15779093, 'global_step': 100}

Below is the ROC Curve

(((((Here is for ROC Curve First))))


Below is for the predicted probs

(((here for pred-prob first)))


MODEL 4
Below are the evaluation metrics:

accuracy	0.812676
accuracy_baseline	0.812676
auc	0.741234
auc_precision_recall	0.300026
average_loss	0.373733
label/mean	0.140112
loss	0.365871
precision	0.000000
prediction/mean	0.156752
recall	0.000000
global_step	100.000000

Below is the ROC Curve

(((here for ROC Curve second)))

Below is for the predicted probs

(((Here is for pred-probs second)))



