A)
Splitting the data is done because otherwise you would only be able to train or test your program, but not both.  If 100% of your data is for training the program, you cant use any of that same data to test what the program was trained on because then it already know the answers.  If you use all your data for testing then the program has nothing to compare it to and thus cant learn/predict.

B)
The RELU function is supposed to set outputs less than 0 to 0 so that the results dont have a downward bias. Softmax helps find the most likely candidate (usually found at the final layer) by setting the highest probability equal to one so that you dont have to write extra code to find the result with the highest probability. There are 10 layers because there are 10 different options that the output could be.

C)
After running through your code you return a c and m value that the loss function then compares to the actual value.  The optimizer then works to attempt to fix the function for another run through to attempt to reach minimum loss.

D)
1) They are 28 x 28 and there are 60,000 in the training set
2) There are also 60,000 labels (1 label for each data point)
3) They are 28 x 28 and there are 10,000 images in the test set
4) Here are my results:
![image](https://user-images.githubusercontent.com/78227412/107536689-0cd9e000-6b90-11eb-98bd-08586309f927.png)




